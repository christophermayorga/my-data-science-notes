{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:34: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:164: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  method='lar', copy_X=True, eps=np.finfo(np.float).eps,\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:281: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_Gram=True, verbose=0,\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:865: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:1121: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, fit_path=True,\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:1149: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, positive=False):\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:1379: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:1621: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  max_n_alphas=1000, n_jobs=None, eps=np.finfo(np.float).eps,\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_least_angle.py:1755: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  eps=np.finfo(np.float).eps, copy_X=True, positive=False):\n",
      "/usr/local/anaconda3/lib/python3.8/site-packages/sklearn/decomposition/_lda.py:28: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  EPS = np.finfo(np.float).eps\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import spacy\n",
    "\n",
    "import pickle\n",
    "import re \n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data\n",
    "Data: https://datapane.com/u/khuyentran1401/reports/Y3Ya6e3/processed-tweets/\n",
    "\n",
    "If you want to get access to the data above and follow along with the article, download the data and put the data in your current directory, then run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "tweets = pd.read_csv('dp-export-8940.csv') #Change this with the name of your downloaded file\n",
    "tweets = tweets.Tweets.values.tolist()\n",
    "\n",
    "# Turn the list of string into a list of tokens\n",
    "tweets = [t.split(',') for t in tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use LDA Model\n",
    "Topic modeling involves counting words and grouping similar word patterns to describe topics within the data. If the model knows the word frequency, and which words often appear in the same document, it will discover patterns that can group different words together.\n",
    "\n",
    "We start with converting a collection of words to a bag of words, which is a list of tuples (word_id, word_frequency). gensim.corpora.Dictionary is a great tool for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 3), (4, 1), (5, 2), (6, 2), (7, 1), (8, 1), (9, 1), (10, 1), (11, 2), (12, 2), (13, 1), (14, 1), (15, 1), (16, 2), (17, 1), (18, 1), (19, 1), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 2), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 2), (35, 1), (36, 2), (37, 1), (38, 9), (39, 1), (40, 1), (41, 1), (42, 2), (43, 2), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 1), (52, 2), (53, 2), (54, 2), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 1), (61, 2), (62, 1), (63, 1), (64, 1), (65, 1), (66, 1), (67, 1), (68, 1), (69, 1), (70, 2), (71, 1), (72, 5), (73, 2), (74, 1), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 1), (82, 5), (83, 1), (84, 2), (85, 1), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 5), (94, 1), (95, 1), (96, 1), (97, 1), (98, 1), (99, 1), (100, 1), (101, 1), (102, 1), (103, 1), (104, 1), (105, 4), (106, 1), (107, 1), (108, 1), (109, 1), (110, 1), (111, 1), (112, 1), (113, 1), (114, 1), (115, 1), (116, 1), (117, 1), (118, 3), (119, 1), (120, 1), (121, 1), (122, 2), (123, 2), (124, 2), (125, 1), (126, 2), (127, 1), (128, 1), (129, 2), (130, 1), (131, 4), (132, 3), (133, 1), (134, 1), (135, 2), (136, 1), (137, 1), (138, 1), (139, 1), (140, 1), (141, 1), (142, 2), (143, 3), (144, 1), (145, 1), (146, 8), (147, 1), (148, 2), (149, 1), (150, 1), (151, 1), (152, 2), (153, 1), (154, 2), (155, 1), (156, 1), (157, 1), (158, 1), (159, 1), (160, 1), (161, 1), (162, 1), (163, 1), (164, 1), (165, 1), (166, 1), (167, 1), (168, 2), (169, 1), (170, 1), (171, 8), (172, 1), (173, 1), (174, 1), (175, 1), (176, 1), (177, 1), (178, 1), (179, 1), (180, 1), (181, 1), (182, 1), (183, 14), (184, 4), (185, 1), (186, 1), (187, 1), (188, 1), (189, 8), (190, 1), (191, 1), (192, 1), (193, 1), (194, 1), (195, 1), (196, 1), (197, 1), (198, 2), (199, 1), (200, 1), (201, 1), (202, 1), (203, 1), (204, 1), (205, 4), (206, 1), (207, 1), (208, 3), (209, 1), (210, 2), (211, 1), (212, 1), (213, 1), (214, 3), (215, 1), (216, 1), (217, 4), (218, 2), (219, 1), (220, 1), (221, 2), (222, 1), (223, 1), (224, 1), (225, 1), (226, 1), (227, 1), (228, 1), (229, 1), (230, 1), (231, 1), (232, 1), (233, 1), (234, 1), (235, 1), (236, 5), (237, 13), (238, 1), (239, 1), (240, 1), (241, 1), (242, 1), (243, 1), (244, 3), (245, 1), (246, 1), (247, 1), (248, 1), (249, 1), (250, 1), (251, 2), (252, 3), (253, 1), (254, 1), (255, 2), (256, 1), (257, 1), (258, 1), (259, 1), (260, 4), (261, 2), (262, 2), (263, 1), (264, 1), (265, 1), (266, 1), (267, 2), (268, 1), (269, 2), (270, 1), (271, 1), (272, 1), (273, 2), (274, 1), (275, 3), (276, 1), (277, 1), (278, 1), (279, 1), (280, 1), (281, 3), (282, 1), (283, 2), (284, 2), (285, 1), (286, 1), (287, 1), (288, 1), (289, 1), (290, 2), (291, 1), (292, 1), (293, 1), (294, 1), (295, 1), (296, 1), (297, 1), (298, 1), (299, 1), (300, 1), (301, 1), (302, 1), (303, 1), (304, 1), (305, 1), (306, 1), (307, 1), (308, 1), (309, 1), (310, 1), (311, 1), (312, 2), (313, 2), (314, 7), (315, 1), (316, 1), (317, 1), (318, 1), (319, 2), (320, 1), (321, 1), (322, 1), (323, 1), (324, 1), (325, 2), (326, 1), (327, 1), (328, 1), (329, 1), (330, 3), (331, 1), (332, 1), (333, 1), (334, 2), (335, 6), (336, 1), (337, 1), (338, 1), (339, 1), (340, 1), (341, 1), (342, 2), (343, 3), (344, 1), (345, 2), (346, 1), (347, 1), (348, 1), (349, 4), (350, 1), (351, 1), (352, 1), (353, 1), (354, 2), (355, 1), (356, 1), (357, 1), (358, 1), (359, 1), (360, 1), (361, 1), (362, 1), (363, 1), (364, 1), (365, 1), (366, 1), (367, 2), (368, 1), (369, 4), (370, 1), (371, 1), (372, 3), (373, 1), (374, 8), (375, 1), (376, 1), (377, 1), (378, 4)]]\n"
     ]
    }
   ],
   "source": [
    "id2word = Dictionary(tweets)\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in tweets]\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do these tuples mean? Let’s convert them into human readable format to understand:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[(\"'d\", 1),\n",
       "  ('-', 1),\n",
       "  ('absolutely', 1),\n",
       "  ('aca', 3),\n",
       "  ('act', 1),\n",
       "  ('action', 2),\n",
       "  ('add', 2),\n",
       "  ('administrative', 1),\n",
       "  ('affordable', 1),\n",
       "  ('allow', 1),\n",
       "  ('amazing', 1),\n",
       "  ('arrive', 2),\n",
       "  ('ask', 2),\n",
       "  ('audits', 1),\n",
       "  ('av', 1),\n",
       "  ('avoid', 1),\n",
       "  ('away', 2),\n",
       "  ('back', 1),\n",
       "  ('ball', 1),\n",
       "  ('baseball', 1),\n",
       "  ('beget', 2),\n",
       "  ('begin', 1),\n",
       "  ('behavior', 1),\n",
       "  ('believe', 1),\n",
       "  ('bid', 1),\n",
       "  ('big', 2),\n",
       "  ('billy', 1),\n",
       "  ('board', 1),\n",
       "  ('bout', 1),\n",
       "  ('branch', 1),\n",
       "  ('break', 1),\n",
       "  ('bring', 1),\n",
       "  ('brother', 1),\n",
       "  ('build', 1),\n",
       "  ('call', 2),\n",
       "  ('can', 1),\n",
       "  ('cap', 2),\n",
       "  ('car', 1),\n",
       "  ('care', 9),\n",
       "  ('cell', 1),\n",
       "  ('certainly', 1),\n",
       "  ('chair', 1),\n",
       "  ('change', 2),\n",
       "  ('chant', 2),\n",
       "  ('chicken', 1),\n",
       "  ('child', 1),\n",
       "  ('chip', 1),\n",
       "  ('choice', 1),\n",
       "  ('choke', 1),\n",
       "  ('chuck', 1),\n",
       "  ('classification', 1),\n",
       "  ('close', 1),\n",
       "  ('come', 2),\n",
       "  ('community', 2),\n",
       "  ('compare', 2),\n",
       "  ('competition', 1),\n",
       "  ('competitively', 1),\n",
       "  ('compliant', 1),\n",
       "  ('conclusion', 1),\n",
       "  ('conference', 1),\n",
       "  ('constituent', 1),\n",
       "  ('continue', 2),\n",
       "  ('continuous', 1),\n",
       "  ('contract', 1),\n",
       "  ('control', 1),\n",
       "  ('count', 1),\n",
       "  ('county', 1),\n",
       "  ('cover', 1),\n",
       "  ('cq', 1),\n",
       "  ('curious', 1),\n",
       "  ('current', 2),\n",
       "  ('dance', 1),\n",
       "  ('day', 5),\n",
       "  ('deal', 2),\n",
       "  ('dear', 1),\n",
       "  ('declaration', 1),\n",
       "  ('dem', 1),\n",
       "  ('demonstration', 1),\n",
       "  ('depart', 1),\n",
       "  ('deregulation', 1),\n",
       "  ('detail', 1),\n",
       "  ('difference', 1),\n",
       "  ('disability', 5),\n",
       "  ('discuss', 1),\n",
       "  ('disruption', 2),\n",
       "  ('do', 1),\n",
       "  ('dock', 1),\n",
       "  ('doctor', 1),\n",
       "  ('don', 1),\n",
       "  ('donation', 1),\n",
       "  ('donut', 1),\n",
       "  ('door', 1),\n",
       "  ('dream', 1),\n",
       "  ('drug', 5),\n",
       "  ('durable', 1),\n",
       "  ('easy', 1),\n",
       "  ('eatright', 1),\n",
       "  ('ehb', 1),\n",
       "  ('eligibility', 1),\n",
       "  ('embrace', 1),\n",
       "  ('enforcement', 1),\n",
       "  ('engage', 1),\n",
       "  ('entertain', 1),\n",
       "  ('equipment', 1),\n",
       "  ('especially', 1),\n",
       "  ('event', 4),\n",
       "  ('excellent', 1),\n",
       "  ('exclusion', 1),\n",
       "  ('extender', 1),\n",
       "  ('eye', 1),\n",
       "  ('fallout', 1),\n",
       "  ('family', 1),\n",
       "  ('far', 1),\n",
       "  ('fate', 1),\n",
       "  ('favor', 1),\n",
       "  ('favorite', 1),\n",
       "  ('feel', 1),\n",
       "  ('file', 1),\n",
       "  ('folk', 3),\n",
       "  ('follow', 1),\n",
       "  ('forever', 1),\n",
       "  ('forward', 1),\n",
       "  ('friend', 2),\n",
       "  ('fun', 2),\n",
       "  ('future', 2),\n",
       "  ('gawk', 1),\n",
       "  ('geek', 2),\n",
       "  ('generally', 1),\n",
       "  ('generation', 1),\n",
       "  ('get', 2),\n",
       "  ('give', 1),\n",
       "  ('go', 4),\n",
       "  ('good', 3),\n",
       "  ('grandfather', 1),\n",
       "  ('grandfathered', 1),\n",
       "  ('great', 2),\n",
       "  ('grind', 1),\n",
       "  ('grow', 1),\n",
       "  ('guess', 1),\n",
       "  ('hall', 1),\n",
       "  ('happen', 1),\n",
       "  ('happiness', 1),\n",
       "  ('happy', 2),\n",
       "  ('hard', 3),\n",
       "  ('harmony', 1),\n",
       "  ('head', 1),\n",
       "  ('health', 8),\n",
       "  ('hearing', 1),\n",
       "  ('here', 2),\n",
       "  ('hero', 1),\n",
       "  ('hhs', 1),\n",
       "  ('hipaa', 1),\n",
       "  ('hit', 2),\n",
       "  ('hold', 1),\n",
       "  ('honor', 2),\n",
       "  ('how', 1),\n",
       "  ('implication', 1),\n",
       "  ('important', 1),\n",
       "  ('incentive', 1),\n",
       "  ('industry', 1),\n",
       "  ('inspire', 1),\n",
       "  ('insurance', 1),\n",
       "  ('insurer', 1),\n",
       "  ('interoperability', 1),\n",
       "  ('interview', 1),\n",
       "  ('iphone', 1),\n",
       "  ('issue', 1),\n",
       "  ('job', 1),\n",
       "  ('just', 2),\n",
       "  ('key', 1),\n",
       "  ('know', 1),\n",
       "  ('law', 8),\n",
       "  ('leadership', 1),\n",
       "  ('learn', 1),\n",
       "  ('leave', 1),\n",
       "  ('let', 1),\n",
       "  ('letter', 1),\n",
       "  ('life', 1),\n",
       "  ('limit', 1),\n",
       "  ('live', 1),\n",
       "  ('long', 1),\n",
       "  ('look', 1),\n",
       "  ('lot', 1),\n",
       "  ('love', 14),\n",
       "  ('make', 4),\n",
       "  ('manage', 1),\n",
       "  ('many', 1),\n",
       "  ('marry', 1),\n",
       "  ('massive', 1),\n",
       "  ('matter', 8),\n",
       "  ('mean', 1),\n",
       "  ('medical', 1),\n",
       "  ('medically', 1),\n",
       "  ('medicare', 1),\n",
       "  ('meet', 1),\n",
       "  ('miss', 1),\n",
       "  ('model', 1),\n",
       "  ('moderate', 1),\n",
       "  ('moment', 2),\n",
       "  ('monster', 1),\n",
       "  ('more', 1),\n",
       "  ('morning', 1),\n",
       "  ('motorcade', 1),\n",
       "  ('move', 1),\n",
       "  ('music', 1),\n",
       "  ('must', 4),\n",
       "  ('necessary', 1),\n",
       "  ('need', 1),\n",
       "  ('new', 3),\n",
       "  ('next', 1),\n",
       "  ('night', 2),\n",
       "  ('non', 1),\n",
       "  ('note', 1),\n",
       "  ('notice', 1),\n",
       "  ('now', 3),\n",
       "  ('nutritionist', 1),\n",
       "  ('off', 1),\n",
       "  ('old', 4),\n",
       "  ('ons', 2),\n",
       "  ('open', 1),\n",
       "  ('order', 1),\n",
       "  ('orderly', 2),\n",
       "  ('oversight', 1),\n",
       "  ('overwhelming', 1),\n",
       "  ('panel', 1),\n",
       "  ('part', 1),\n",
       "  ('patent', 1),\n",
       "  ('path', 1),\n",
       "  ('pay', 1),\n",
       "  ('payment', 1),\n",
       "  ('peace', 1),\n",
       "  ('people', 1),\n",
       "  ('period', 1),\n",
       "  ('phase', 1),\n",
       "  ('phone', 1),\n",
       "  ('place', 1),\n",
       "  ('plan', 5),\n",
       "  ('policy', 13),\n",
       "  ('pool', 1),\n",
       "  ('pose', 1),\n",
       "  ('positive', 1),\n",
       "  ('poster', 1),\n",
       "  ('present', 1),\n",
       "  ('press', 1),\n",
       "  ('pricing', 3),\n",
       "  ('primary', 1),\n",
       "  ('professional', 1),\n",
       "  ('program', 1),\n",
       "  ('project', 1),\n",
       "  ('promise', 1),\n",
       "  ('promote', 1),\n",
       "  ('protester', 2),\n",
       "  ('provider', 3),\n",
       "  ('pull', 1),\n",
       "  ('qualified', 1),\n",
       "  ('question', 2),\n",
       "  ('quick', 1),\n",
       "  ('quote', 1),\n",
       "  ('rap', 1),\n",
       "  ('rate', 1),\n",
       "  ('read', 4),\n",
       "  ('real', 2),\n",
       "  ('really', 2),\n",
       "  ('rebate', 1),\n",
       "  ('reference', 1),\n",
       "  ('reflection', 1),\n",
       "  ('reform', 1),\n",
       "  ('regulation', 2),\n",
       "  ('reimbursement', 1),\n",
       "  ('repeal', 2),\n",
       "  ('replace', 1),\n",
       "  ('replacement', 1),\n",
       "  ('report', 1),\n",
       "  ('republican', 2),\n",
       "  ('research', 1),\n",
       "  ('review', 3),\n",
       "  ('right', 1),\n",
       "  ('rip', 1),\n",
       "  ('rock', 1),\n",
       "  ('roll', 1),\n",
       "  ('room', 1),\n",
       "  ('rule', 3),\n",
       "  ('rulemake', 1),\n",
       "  ('rural', 2),\n",
       "  ('s', 2),\n",
       "  ('sausage', 1),\n",
       "  ('say', 1),\n",
       "  ('scandal', 1),\n",
       "  ('scary', 1),\n",
       "  ('scene', 1),\n",
       "  ('see', 2),\n",
       "  ('selfie', 1),\n",
       "  ('send', 1),\n",
       "  ('set', 1),\n",
       "  ('share', 1),\n",
       "  ('shkreli', 1),\n",
       "  ('shoe', 1),\n",
       "  ('shoot', 1),\n",
       "  ('should', 1),\n",
       "  ('shout', 1),\n",
       "  ('silver', 1),\n",
       "  ('sing', 1),\n",
       "  ('singe', 1),\n",
       "  ('sirius', 1),\n",
       "  ('sit', 1),\n",
       "  ('sketch', 1),\n",
       "  ('slice', 1),\n",
       "  ('slogan', 1),\n",
       "  ('smarter', 1),\n",
       "  ('so', 1),\n",
       "  ('sole', 1),\n",
       "  ('solution', 1),\n",
       "  ('son', 2),\n",
       "  ('spark', 2),\n",
       "  ('speak', 7),\n",
       "  ('speaking', 1),\n",
       "  ('specific', 1),\n",
       "  ('speech', 1),\n",
       "  ('spending', 1),\n",
       "  ('spot', 2),\n",
       "  ('spread', 1),\n",
       "  ('staffer', 1),\n",
       "  ('stage', 1),\n",
       "  ('stand', 1),\n",
       "  ('standard', 1),\n",
       "  ('start', 2),\n",
       "  ('stay', 1),\n",
       "  ('step', 1),\n",
       "  ('story', 1),\n",
       "  ('strategy', 1),\n",
       "  ('stuff', 3),\n",
       "  ('supergeek', 1),\n",
       "  ('support', 1),\n",
       "  ('table', 1),\n",
       "  ('take', 2),\n",
       "  ('talk', 6),\n",
       "  ('target', 1),\n",
       "  ('teach', 1),\n",
       "  ('teenager', 1),\n",
       "  ('thank', 1),\n",
       "  ('therapy', 1),\n",
       "  ('thing', 1),\n",
       "  ('think', 2),\n",
       "  ('thought', 3),\n",
       "  ('time', 1),\n",
       "  ('tomorrow', 2),\n",
       "  ('totally', 1),\n",
       "  ('town', 1),\n",
       "  ('trade', 1),\n",
       "  ('transition', 4),\n",
       "  ('transitioning', 1),\n",
       "  ('transparency', 1),\n",
       "  ('transparent', 1),\n",
       "  ('true', 1),\n",
       "  ('truly', 2),\n",
       "  ('try', 1),\n",
       "  ('turret', 1),\n",
       "  ('tweet', 1),\n",
       "  ('tweeting', 1),\n",
       "  ('ugh', 1),\n",
       "  ('underwear', 1),\n",
       "  ('upcoming', 1),\n",
       "  ('use', 1),\n",
       "  ('utilization', 1),\n",
       "  ('value', 1),\n",
       "  ('version', 1),\n",
       "  ('veteran', 1),\n",
       "  ('view', 2),\n",
       "  ('walk', 1),\n",
       "  ('way', 4),\n",
       "  ('week', 1),\n",
       "  ('well', 1),\n",
       "  ('will', 3),\n",
       "  ('wonder', 1),\n",
       "  ('work', 8),\n",
       "  ('world', 1),\n",
       "  ('writing', 1),\n",
       "  ('wrong', 1),\n",
       "  ('year', 4)]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[(id2word[i], freq) for i, freq in doc] for doc in corpus[:1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let’s build an LDA topic model. We will use gensim.models.ldamodel.LdaModel for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.144*\"video\" + 0.127*\"like\" + 0.098*\"follow\" + 0.082*\"check\" + '\n",
      "  '0.045*\"people\" + 0.042*\"automatically\" + 0.029*\"unfollowed\" + '\n",
      "  '0.024*\"follower\" + 0.021*\"person\" + 0.016*\"new\"'),\n",
      " (1,\n",
      "  '0.040*\"game\" + 0.033*\"play\" + 0.027*\"win\" + 0.023*\"team\" + 0.018*\"player\" + '\n",
      "  '0.015*\"good\" + 0.014*\"great\" + 0.013*\"half\" + 0.012*\"season\" + 0.011*\"fan\"'),\n",
      " (2,\n",
      "  '0.017*\"go\" + 0.015*\"good\" + 0.013*\"love\" + 0.011*\"think\" + 0.011*\"know\" + '\n",
      "  '0.010*\"watch\" + 0.010*\"time\" + 0.008*\"look\" + 0.008*\"come\" + 0.007*\"year\"'),\n",
      " (3,\n",
      "  '0.140*\"more\" + 0.050*\"today\" + 0.017*\"cancer\" + 0.015*\"pisce\" + '\n",
      "  '0.011*\"capricorn\" + 0.011*\"aquarius\" + 0.009*\"arie\" + 0.007*\"feel\" + '\n",
      "  '0.006*\"day\" + 0.005*\"gemini\"'),\n",
      " (4,\n",
      "  '0.000*\"follow\" + 0.000*\"thx\" + 0.000*\"people\" + 0.000*\"twitt\" + '\n",
      "  '0.000*\"trump\" + 0.000*\"know\" + 0.000*\"time\" + 0.000*\"thank\" + 0.000*\"go\" + '\n",
      "  '0.000*\"need\"'),\n",
      " (5,\n",
      "  '0.034*\"trump\" + 0.014*\"people\" + 0.011*\"vote\" + 0.011*\"think\" + '\n",
      "  '0.010*\"know\" + 0.008*\"country\" + 0.008*\"need\" + 0.008*\"right\" + 0.007*\"go\" '\n",
      "  '+ 0.006*\"ban\"'),\n",
      " (6,\n",
      "  '0.027*\"thank\" + 0.021*\"how\" + 0.019*\"new\" + 0.017*\"late\" + 0.015*\"learn\" + '\n",
      "  '0.013*\"business\" + 0.010*\"social\" + 0.009*\"design\" + 0.009*\"app\" + '\n",
      "  '0.008*\"why\"'),\n",
      " (7,\n",
      "  '0.019*\"thank\" + 0.014*\"day\" + 0.011*\"good\" + 0.010*\"new\" + 0.010*\"today\" + '\n",
      "  '0.010*\"time\" + 0.009*\"year\" + 0.009*\"look\" + 0.009*\"love\" + 0.009*\"great\"'),\n",
      " (8,\n",
      "  '0.039*\"great\" + 0.011*\"forward\" + 0.010*\"look\" + 0.009*\"event\" + '\n",
      "  '0.009*\"interesting\" + 0.008*\"new\" + 0.008*\"host\" + 0.008*\"review\" + '\n",
      "  '0.007*\"good\" + 0.007*\"earn\"'),\n",
      " (9,\n",
      "  '0.009*\"say\" + 0.006*\"people\" + 0.006*\"woman\" + 0.005*\"need\" + 0.005*\"-\" + '\n",
      "  '0.005*\"change\" + 0.005*\"read\" + 0.005*\"year\" + 0.004*\"world\" + '\n",
      "  '0.004*\"support\"')]\n"
     ]
    }
   ],
   "source": [
    "# Build LDA model\n",
    "lda_model = LdaModel(corpus=corpus,\n",
    "                   id2word=id2word,\n",
    "                   num_topics=10, \n",
    "                   random_state=0,\n",
    "                   chunksize=100,\n",
    "                   alpha='auto',\n",
    "                   per_word_topics=True)\n",
    "\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the patterns we can see?\n",
    "0. Following\n",
    "1. Gameplay\n",
    "2. Good time?\n",
    "3. Astrology\n",
    "4. Thanks for following\n",
    "5. Voting\n",
    "6. Business\n",
    "7. New year\n",
    "8. Not sure\n",
    "9. World leaders ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.3577702217149491\n"
     ]
    }
   ],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=tweets, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
